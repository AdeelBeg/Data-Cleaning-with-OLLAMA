# Copy to .env for local GenAI runs.
#
# Requirements:
#   1) Install Ollama
#   2) Run: ollama serve
#   3) Run: ollama pull qwen2.5:7b

# Ollama base URL (default is http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# Default model for GenAI-assisted cleaning
OLLAMA_MODEL=qwen2.5:7b
